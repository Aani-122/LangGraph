{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi there\n"
     ]
    }
   ],
   "source": [
    "print(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"google_genai:gemini-2.0-flash\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END, START, StateGraph, MessagesState\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"call this tool to get the weather of a city\"\"\"\n",
    "    if city.lower() == \"mumbai\":\n",
    "        return \"22 degree celsius\"\n",
    "    elif city.lower() == \"delhi\":\n",
    "        return \"24 degree celsius\"\n",
    "    else:\n",
    "        return \"I don't know the weather of this city\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'22 degree celsius'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather.invoke(\"Mumbai\") # this is runable due to @tool decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[get_weather]\n",
    "def call_model(state: MessagesState):\n",
    "    messages=state[\"messages\"]\n",
    "    response=llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state: MessagesState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"  # Return the string name of the tool node\n",
    "    else:\n",
    "        return \"end\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a51b0e0970>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow=StateGraph(MessagesState)\n",
    "tool_node=ToolNode(tools)\n",
    "\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tool\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2a51b0e0970>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",should_continue,\n",
    "    {'tools': 'tool',\n",
    "      'end': END}\n",
    "      )\n",
    "\n",
    "workflow.add_edge(\"tool\", \"agent\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages=[HumanMessage(content=\"What is the weather in Mumbai?\")]\n",
    "messages1=[HumanMessage(content=\"hello how are you?\")]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is the weather in Mumbai?', additional_kwargs={}, response_metadata={}, id='793b03a4-e5d7-4e53-b6f8-bf7f7f2acd93'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Mumbai\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--edcd163c-2de7-478d-af2c-0519043e0768-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Mumbai'}, 'id': '1b7e3952-855e-476a-a001-d5ab51998ee2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 24, 'output_tokens': 5, 'total_tokens': 29, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='22 degree celsius', name='get_weather', id='d9ef1bb1-fbdc-4c8e-ae13-91675dd70763', tool_call_id='1b7e3952-855e-476a-a001-d5ab51998ee2'),\n",
       "  AIMessage(content='The weather in Mumbai is 22 degree celsius.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--e0c3c461-b941-429d-b9ac-89744f0801cb-0', usage_metadata={'input_tokens': 37, 'output_tokens': 12, 'total_tokens': 49, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='hello how are you?', additional_kwargs={}, response_metadata={}, id='b23ac6aa-beee-4bf4-9257-4fd74b307c28'),\n",
       "  AIMessage(content='I am doing well, thank you for asking. How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--52ff9dcd-2e55-4c79-99de-2d7354f06580-0', usage_metadata={'input_tokens': 22, 'output_tokens': 18, 'total_tokens': 40, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\"messages\":messages1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that we dont have memory in above case so we can't ask any follow up question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for adding memory to the agent\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "checkpointer=MemorySaver()\n",
    "\n",
    "workflow=StateGraph(MessagesState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {'tools': 'tools',\n",
    "      'end': END},\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "graph=workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "#graph.invoke({\"messages\": [HumanMessage(content=\"What is the weather in Tokyo?\")]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input=\" I am in Mumbai What is the weather here?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=' I am in Mumbai What is the weather here?', additional_kwargs={}, response_metadata={}, id='ad25446b-238d-4457-a66c-7237ad207cd3'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Mumbai\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--049ae94c-b724-4e07-9a19-e30362f5f0e3-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Mumbai'}, 'id': '7e1ffe7a-3e2e-4530-8541-927f5e198e0b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 27, 'output_tokens': 5, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='22 degree celsius', name='get_weather', id='0a4f2aab-909a-49f3-aeb5-dd80ae7fd7d1', tool_call_id='7e1ffe7a-3e2e-4530-8541-927f5e198e0b'),\n",
       "  AIMessage(content='The weather in Mumbai is 22 degree celsius.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--86708abd-d032-497b-bc81-e6b425000ec3-0', usage_metadata={'input_tokens': 40, 'output_tokens': 12, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user_input = \"Hi there! My name is Will.\"\n",
    "graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"4\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=' I am in Mumbai What is the weather here?', additional_kwargs={}, response_metadata={}, id='ad25446b-238d-4457-a66c-7237ad207cd3'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather', 'arguments': '{\"city\": \"Mumbai\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--049ae94c-b724-4e07-9a19-e30362f5f0e3-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'Mumbai'}, 'id': '7e1ffe7a-3e2e-4530-8541-927f5e198e0b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 27, 'output_tokens': 5, 'total_tokens': 32, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='22 degree celsius', name='get_weather', id='0a4f2aab-909a-49f3-aeb5-dd80ae7fd7d1', tool_call_id='7e1ffe7a-3e2e-4530-8541-927f5e198e0b'),\n",
       "  AIMessage(content='The weather in Mumbai is 22 degree celsius.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--86708abd-d032-497b-bc81-e6b425000ec3-0', usage_metadata={'input_tokens': 40, 'output_tokens': 12, 'total_tokens': 52, 'input_token_details': {'cache_read': 0}}),\n",
       "  HumanMessage(content='do I need to wear a jacket today?', additional_kwargs={}, response_metadata={}, id='2c963fe9-ffe7-4ba2-aa49-5344fa6533f7'),\n",
       "  AIMessage(content='The weather in Mumbai is 22 degree celsius, which is generally warm. A jacket is probably not necessary.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--78f56865-9e88-4cdc-b3ab-45f40afddd4a-0', usage_metadata={'input_tokens': 60, 'output_tokens': 24, 'total_tokens': 84, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"do I need to wear a jacket today?\"\n",
    "graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    {\"configurable\": {\"thread_id\": \"4\"}},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    210\u001b[0m         error_list,\n\u001b[0;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    212\u001b[0m         original_timeout,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi there! My name is Will.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# The config is the **second positional argument** to stream() or invoke()!\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m events \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[0;32m     10\u001b[0m     event[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2721\u001b[0m     config,\n\u001b[0;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2729\u001b[0m ):\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2441\u001b[0m         ):\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: MessagesState):\n\u001b[0;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     response\u001b[38;5;241m=\u001b[39m\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5424\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5426\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5432\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5434\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1255\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1253\u001b[0m         )\n\u001b[1;32m-> 1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    777\u001b[0m                 m,\n\u001b[0;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    781\u001b[0m             )\n\u001b[0;32m    782\u001b[0m         )\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1342\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1318\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1330\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m   1331\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m   1332\u001b[0m         messages,\n\u001b[0;32m   1333\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m   1341\u001b[0m     )\n\u001b[1;32m-> 1342\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m   1343\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m   1344\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1345\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m   1346\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:210\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:204\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.invoke(\n",
    "    {\"messages\": messages},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:192\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:868\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 868\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    293\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    210\u001b[0m         error_list,\n\u001b[0;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    212\u001b[0m         original_timeout,\n\u001b[0;32m    213\u001b[0m     )\n\u001b[1;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigurable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2716\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2717\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 2719\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   2720\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   2721\u001b[0m     config,\n\u001b[0;32m   2722\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[0;32m   2723\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   2724\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   2725\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   2726\u001b[0m     checkpoint_during\u001b[38;5;241m=\u001b[39mcheckpoint_during,\n\u001b[0;32m   2727\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[0;32m   2728\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2729\u001b[0m ):\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   2731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2732\u001b[0m             \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m   2733\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m (ints \u001b[38;5;241m:=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mget(INTERRUPT)) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2734\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2434\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2435\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2436\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2437\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2438\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2439\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2440\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2441\u001b[0m         ):\n\u001b[0;32m   2442\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2443\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2444\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    159\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m, in \u001b[0;36mcall_model\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: MessagesState):\n\u001b[0;32m      3\u001b[0m     messages\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m     response\u001b[38;5;241m=\u001b[39m\u001b[43mllm_with_tools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [response]}\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5431\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5424\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5426\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5429\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5430\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5432\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5433\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5434\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1255\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI.invoke\u001b[1;34m(self, input, config, code_execution, stop, **kwargs)\u001b[0m\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1251\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTools are already defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution tool can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt be defined\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1253\u001b[0m         )\n\u001b[1;32m-> 1255\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:372\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    368\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    369\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 372\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    373\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    374\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    375\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    376\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    377\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    378\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    379\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    380\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    381\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    382\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 776\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    777\u001b[0m                 m,\n\u001b[0;32m    778\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    779\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    780\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    781\u001b[0m             )\n\u001b[0;32m    782\u001b[0m         )\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1023\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1024\u001b[0m     )\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:1342\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1318\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1330\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m   1331\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m   1332\u001b[0m         messages,\n\u001b[0;32m   1333\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1340\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m   1341\u001b[0m     )\n\u001b[1;32m-> 1342\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m   1343\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m   1344\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1345\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m   1346\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m   1347\u001b[0m     )\n\u001b[0;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:210\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:338\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    336\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    337\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:400\u001b[0m, in \u001b[0;36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetryCallState\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mis_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mretry_run_result):\n\u001b[1;32m--> 400\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutcome\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\concurrent\\futures\\_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\tenacity\\__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\projects\\LangGraph\\venv\\lib\\site-packages\\langchain_google_genai\\chat_models.py:204\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    205\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    206\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[1;31mChatGoogleGenerativeAIError\u001b[0m: Invalid argument provided to Gemini: 400 * GenerateContentRequest.contents[2].parts: contents.parts must not be empty.\n"
     ]
    }
   ],
   "source": [
    "graph.invoke({\"messages\": messages},\n",
    "             config={\"configurable\": {\"thread_id\": 1}})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
